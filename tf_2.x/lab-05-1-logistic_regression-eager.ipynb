{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 05 Logistic Classification(Regression) - Eager Execution\n",
    "* Logistic Classfication은 True or False와 같은 Binary나 복수개의 다항 분류에 쓰입니다 (Bernoulli Distribution)\n",
    "\n",
    "### 기본 Library 선언 및 Tensorflow 버전 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(777)  # for reproducibility\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 강의에 설명할 Data입니다\n",
    "* x_data가 2차원 배열이기에 2차원 공간에 표현하여 x1과 x2를 기준으로 y_data 0과 1로 구분하는 예제입니다\n",
    "* Logistic Classification 통해 보라색과 노란색 y_data(Label)을 구분해 보겠습니다.\n",
    "* Test 데이터는 붉은색의 위치와 같이 추론시 1의 값을 가지게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train = [[1., 2.],\n",
    "          [2., 3.],\n",
    "          [3., 1.],\n",
    "          [4., 3.],\n",
    "          [5., 3.],\n",
    "          [6., 2.]]\n",
    "y_train = [[0.],\n",
    "          [0.],\n",
    "          [0.],\n",
    "          [1.],\n",
    "          [1.],\n",
    "          [1.]]\n",
    "\n",
    "x_test = [[5.,2.]]\n",
    "y_test = [[1.]]\n",
    "\n",
    "\n",
    "x1 = [x[0] for x in x_train]\n",
    "x2 = [x[1] for x in x_train]\n",
    "\n",
    "colors = [int(y[0] % 3) for y in y_train]\n",
    "plt.scatter(x1,x2, c=colors , marker='^')\n",
    "plt.scatter(x_test[0][0],x_test[0][1], c=\"red\")\n",
    "\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Tensorflow Eager\n",
    "### 위 Data를 기준으로 가설의 검증을 통해 Logistic Classification 모델을 만들도록 하겠습니다\n",
    "* Tensorflow data API를 통해 학습시킬 값들을 담는다 (Batch Size는 한번에 학습시킬 Size로 정한다)\n",
    "* features,labels는 실재 학습에 쓰일 Data (연산을 위해 Type를 맞춰준다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(len(x_train))#.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위 Data를 기준으로 가설의 검증을 통해 Logistic Classification 모델을 만들도록 하겠습니다\n",
    "* W와 b은 학습을 통해 생성되는 모델에 쓰이는 Wegith와 Bias (초기값을 variable : 0이나 Random값으로 가능 tf.random_normal([2, 1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([2,1]), name='weight')\n",
    "b = tf.Variable(tf.zeros([1]), name='bias')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid 함수를 가설로 선언합니다\n",
    "* Sigmoid는 아래 그래프와 같이 0과 1의 값만을 리턴합니다 tf.sigmoid(tf.matmul(X, W) + b)와 같습니다\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "sigmoid(x) & = \\frac{1}{1+e^{-x}}  \\\\\\\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "![sigmoid](https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(features):\n",
    "    hypothesis  = tf.divide(1., 1. + tf.exp(tf.matmul(features, W) + b))\n",
    "    return hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가설을 검증할 Cost 함수를 정의합니다\n",
    "$$\n",
    "\\begin{align}\n",
    "cost(h(x),y) & = −log(h(x))  &  if  &  y=1 \\\\\\\\\\\n",
    "cost(h(x),y) & = -log(1−h(x))  &  if  &  y=0\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 위 두수식을 합치면 아래과 같습니다\n",
    "$$\n",
    "\\begin{align}\n",
    "cost(h(x),y) & = −y log(h(x))−(1−y)log(1−h(x))\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(hypothesis, features, labels):\n",
    "    cost = -tf.reduce_mean(labels * tf.math.log(logistic_regression(features)) + (1 - labels) * tf.math.log(1 - hypothesis))\n",
    "    return cost\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추론한 값은 0.5를 기준(Sigmoid 그래프 참조)로 0과 1의 값을 리턴합니다.\n",
    "* Sigmoid 함수를 통해 예측값이 0.5보다 크면 1을 반환하고 0.5보다 작으면 0으로 반환합니다.\n",
    "* 가설을 통해 실재 값과 비교한 정확도를 측정합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(hypothesis, labels):\n",
    "    predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.int32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientTape를 통해 경사값을 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss_fn(logistic_regression(features),features,labels)\n",
    "    return tape.gradient(loss_value, [W,b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습을 실행합니다.\n",
    "* 위의 Data를 Cost함수를 통해 학습시킨 후 모델을 생성합니다. \n",
    "* 새로운 Data를 통한 검증 수행 [5,2]의 Data로 테스트 수행 (그래프상 1이 나와야 정상입니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Loss: 0.6874\n",
      "Iter: 100, Loss: 0.5776\n",
      "Iter: 200, Loss: 0.5349\n",
      "Iter: 300, Loss: 0.5054\n",
      "Iter: 400, Loss: 0.4838\n",
      "Iter: 500, Loss: 0.4671\n",
      "Iter: 600, Loss: 0.4535\n",
      "Iter: 700, Loss: 0.4420\n",
      "Iter: 800, Loss: 0.4319\n",
      "Iter: 900, Loss: 0.4228\n",
      "Iter: 1000, Loss: 0.4144\n",
      "Testset Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1001\n",
    "\n",
    "for step in range(EPOCHS):\n",
    "    for features, labels  in iter(dataset):\n",
    "        grads = grad(logistic_regression(features), features, labels)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads,[W,b]))\n",
    "        if step % 100 == 0:\n",
    "            print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_fn(logistic_regression(features),features,labels)))\n",
    "test_acc = accuracy_fn(logistic_regression(x_test),y_test)\n",
    "print(\"Testset Accuracy: {:.4f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
