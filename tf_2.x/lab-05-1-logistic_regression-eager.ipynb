{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 05 Logistic Classification(Regression) - Eager Execution\n",
    "* Logistic Classfication은 True or False와 같은 Binary나 복수개의 다항 분류에 쓰입니다 (Bernoulli Distribution)\n",
    "\n",
    "### 기본 Library 선언 및 Tensorflow 버전 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-alpha0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(777)  # for reproducibility\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 강의에 설명할 Data입니다\n",
    "* x_data가 2차원 배열이기에 2차원 공간에 표현하여 x1과 x2를 기준으로 y_data 0과 1로 구분하는 예제입니다\n",
    "* Logistic Classification 통해 보라색과 노란색 y_data(Label)을 구분해 보겠습니다.\n",
    "* Test 데이터는 붉은색의 위치와 같이 추론시 1의 값을 가지게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train = [[1., 2.],\n",
    "          [2., 3.],\n",
    "          [3., 1.],\n",
    "          [4., 3.],\n",
    "          [5., 3.],\n",
    "          [6., 2.]]\n",
    "y_train = [[0.],\n",
    "          [0.],\n",
    "          [0.],\n",
    "          [1.],\n",
    "          [1.],\n",
    "          [1.]]\n",
    "\n",
    "x_test = [[5.,2.]]\n",
    "y_test = [[1.]]\n",
    "\n",
    "\n",
    "x1 = [x[0] for x in x_train]\n",
    "x2 = [x[1] for x in x_train]\n",
    "\n",
    "colors = [int(y[0] % 3) for y in y_train]\n",
    "plt.scatter(x1,x2, c=colors , marker='^')\n",
    "plt.scatter(x_test[0][0],x_test[0][1], c=\"red\")\n",
    "\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Tensorflow Eager\n",
    "### 위 Data를 기준으로 가설의 검증을 통해 Logistic Classification 모델을 만들도록 하겠습니다\n",
    "* Tensorflow data API를 통해 학습시킬 값들을 담는다 (Batch Size는 한번에 학습시킬 Size로 정한다)\n",
    "* features,labels는 실재 학습에 쓰일 Data (연산을 위해 Type를 맞춰준다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(len(x_train))#.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위 Data를 기준으로 가설의 검증을 통해 Logistic Classification 모델을 만들도록 하겠습니다\n",
    "* W와 b은 학습을 통해 생성되는 모델에 쓰이는 Wegith와 Bias (초기값을 variable : 0이나 Random값으로 가능 tf.random_normal([2, 1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([2,1]), name='weight')\n",
    "b = tf.Variable(tf.zeros([1]), name='bias')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid 함수를 가설로 선언합니다\n",
    "* Sigmoid는 아래 그래프와 같이 0과 1의 값만을 리턴합니다 tf.sigmoid(tf.matmul(X, W) + b)와 같습니다\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "sigmoid(x) & = \\frac{1}{1+e^{-x}}  \\\\\\\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "![sigmoid](https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(features):\n",
    "    hypothesis = tf.divide(1., 1.+tf.exp(tf.matmul(features, W) + b))\n",
    "    return hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가설을 검증할 Cost 함수를 정의합니다\n",
    "$$\n",
    "\\begin{align}\n",
    "cost(h(x),y) & = −log(h(x))  &  if  &  y=1 \\\\\\\\\\\n",
    "cost(h(x),y) & = -log(1−h(x))  &  if  &  y=0\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 위 두수식을 합치면 아래과 같습니다\n",
    "$$\n",
    "\\begin{align}\n",
    "cost(h(x),y) & = −y log(h(x))−(1−y)log(1−h(x))\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(hypothesis, features, labels):\n",
    "    cost = tf.reduce_mean(-labels * tf.math.log(logistic_regression(features)) - (1- labels) * tf.math.log(1 - logistic_regression(features))) # logistic_regression(features) = hypothesis 다.\n",
    "    return cost\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate = 0.01) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추론한 값은 0.5를 기준(Sigmoid 그래프 참조)로 0과 1의 값을 리턴합니다.\n",
    "* Sigmoid 함수를 통해 예측값이 0.5보다 크면 1을 반환하고 0.5보다 작으면 0으로 반환합니다.\n",
    "* 가설을 통해 실재 값과 비교한 정확도를 측정합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(hypothesis, labels):\n",
    "    predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32) \n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype = tf.int32)) \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientTape를 통해 경사값을 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(hypothesis, features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss_fn(logistic_regression(features), features, labels)\n",
    "    return tape.gradient(loss_value, [W, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습을 실행합니다.\n",
    "* 위의 Data를 Cost함수를 통해 학습시킨 후 모델을 생성합니다. \n",
    "* 새로운 Data를 통한 검증 수행 [5,2]의 Data로 테스트 수행 (그래프상 1이 나와야 정상입니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Loss: 0.6874\n",
      "Iter: 100, Loss: 0.5776\n",
      "Iter: 200, Loss: 0.5349\n",
      "Iter: 300, Loss: 0.5054\n",
      "Iter: 400, Loss: 0.4838\n",
      "Iter: 500, Loss: 0.4671\n",
      "Iter: 600, Loss: 0.4535\n",
      "Iter: 700, Loss: 0.4420\n",
      "Iter: 800, Loss: 0.4319\n",
      "Iter: 900, Loss: 0.4228\n",
      "Iter: 1000, Loss: 0.4144\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1001\n",
    "\n",
    "for step in range(EPOCHS):\n",
    "    for features, labels in iter(dataset):\n",
    "        grads = grad(logistic_regression(features), features, labels)\n",
    "        optimizer.apply_gradients(grads_and_vars = zip(grads, [W, b]))\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_fn(logistic_regression(features),features,labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
